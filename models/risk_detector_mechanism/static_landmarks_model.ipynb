{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b816e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ast\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5596d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../assets/labeled_dataset.csv')\n",
    "def is_float(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "dataset['landmarks'] = dataset['landmarks'].apply(lambda arr: np.array([float(n) for n in arr.split() if is_float(n)]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff30d65c",
   "metadata": {},
   "source": [
    "### Hypothesis:\n",
    "\t- We can calculate the average of each landmark for a sequence of data\n",
    "\t- And have the average joint position for each joint in a sequence of 5 frames\n",
    "\t- We can train a regular NN to do classification or also regression because we would also have a good or bad ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a73459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>group</th>\n",
       "      <th>frame</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 51.864, 255.39, 103.26, 469.14, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 82.174, 253.09, 164.85, 471.52, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.0, 118.78, 253.62, 238.0, 472.77, 0.93...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 155.33, 253.25, 309.87, 471.26, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.0, 0.0, 181.27, 252.78, 362.54, 470.1, 0.94...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>[0.0, 0.0, 195.85, 253.87, 332.73, 475.31, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>[0.0, 0.0, 232.89, 279.67, 260.39, 426.85, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>[0.0, 0.0, 278.54, 286.11, 245.45, 414.3, 0.94...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>[0.0, 0.0, 291.42, 293.58, 253.71, 398.67, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>[0.0, 0.0, 295.83, 291.14, 241.17, 403.39, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>[0.0, 0.0, 291.94, 289.07, 259.71, 408.98, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.0, 0.0, 293.24, 286.58, 284.89, 414.12, 0.9...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video  group  frame   \n",
       "0   video56.mp4      1      5  \\\n",
       "1   video56.mp4      1     11   \n",
       "2   video56.mp4      1     17   \n",
       "3   video56.mp4      1     23   \n",
       "4   video56.mp4      1     29   \n",
       "5   video56.mp4      1     35   \n",
       "6   video56.mp4      1     41   \n",
       "7   video56.mp4      1     47   \n",
       "8   video56.mp4      1     53   \n",
       "9   video56.mp4      1     59   \n",
       "10  video56.mp4      2     71   \n",
       "11  video56.mp4      2     77   \n",
       "\n",
       "                                            landmarks Label  \n",
       "0   [0.0, 0.0, 51.864, 255.39, 103.26, 469.14, 0.9...   bad  \n",
       "1   [0.0, 0.0, 82.174, 253.09, 164.85, 471.52, 0.9...   bad  \n",
       "2   [0.0, 0.0, 118.78, 253.62, 238.0, 472.77, 0.93...   bad  \n",
       "3   [0.0, 0.0, 155.33, 253.25, 309.87, 471.26, 0.9...   bad  \n",
       "4   [0.0, 0.0, 181.27, 252.78, 362.54, 470.1, 0.94...   bad  \n",
       "5   [0.0, 0.0, 195.85, 253.87, 332.73, 475.31, 0.9...   bad  \n",
       "6   [0.0, 0.0, 232.89, 279.67, 260.39, 426.85, 0.9...   bad  \n",
       "7   [0.0, 0.0, 278.54, 286.11, 245.45, 414.3, 0.94...   bad  \n",
       "8   [0.0, 0.0, 291.42, 293.58, 253.71, 398.67, 0.9...   bad  \n",
       "9   [0.0, 0.0, 295.83, 291.14, 241.17, 403.39, 0.9...   bad  \n",
       "10  [0.0, 0.0, 291.94, 289.07, 259.71, 408.98, 0.9...   bad  \n",
       "11  [0.0, 0.0, 293.24, 286.58, 284.89, 414.12, 0.9...   bad  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44eaec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fdf3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouing data\n",
    "grouped = dataset.groupby(['video', 'group'])\n",
    "static_transformed = {'video': [], 'group': [], 'landmark': [], 'label': []}\n",
    "\n",
    "for (video, group), group_data in grouped:\n",
    "    # Categorizing labels to get percentage\n",
    "    sequence_labels = group_data['Label'].values\n",
    "    binary_labels = np.array([1 if label == 'good' else 0 for label in sequence_labels])\n",
    "        \n",
    "    # Get a static landmark set\n",
    "    # TODO: Enhance this static landmark (fill empty spaces in some cases + other processing)\n",
    "    sequence_landmarks = group_data['landmarks'].values\n",
    "    average_landmarks = np.mean(sequence_landmarks, axis=0)\n",
    "    probability_good = np.mean(binary_labels)\n",
    "    \n",
    "    static_transformed['video'] += [video]\n",
    "    static_transformed['group'] += [group]\n",
    "    static_transformed['landmark'] += [average_landmarks]\n",
    "    static_transformed['label'] += [probability_good]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db131a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "static = pd.DataFrame(data=static_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca0c3eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>group</th>\n",
       "      <th>landmark</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video17.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video17.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video17.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video17.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video17.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>video56.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 272.42099999999994, 257.643, 371.19...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           video  group                                           landmark   \n",
       "0    video17.mp4      1  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...  \\\n",
       "1    video17.mp4      2  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "2    video17.mp4      3  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "3    video17.mp4      4  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "4    video17.mp4      5  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "..           ...    ...                                                ...   \n",
       "414  video56.mp4      4  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "415  video56.mp4      5  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "416  video56.mp4      6  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "417  video56.mp4      7  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "418  video56.mp4      8  [0.0, 0.0, 272.42099999999994, 257.643, 371.19...   \n",
       "\n",
       "     label  \n",
       "0      0.1  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "414    0.5  \n",
       "415    0.0  \n",
       "416    0.0  \n",
       "417    0.0  \n",
       "418    0.0  \n",
       "\n",
       "[419 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43514f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(static['landmark'].tolist())\n",
    "y = np.array(static['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f0266d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalizing the landmarks\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a3ada25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_prob):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a79f4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_size = 32\n",
    "dropout_prob = 0.25  # Adjust dropout probability\n",
    "\n",
    "net = Net(input_size, hidden_size, dropout_prob)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b02402a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.3202, Train Accuracy: 0.7672\n",
      "Epoch [2/50], Loss: 0.3167, Train Accuracy: 0.7672\n",
      "Epoch [3/50], Loss: 0.3170, Train Accuracy: 0.7672\n",
      "Epoch [4/50], Loss: 0.3176, Train Accuracy: 0.7672\n",
      "Epoch [5/50], Loss: 0.3164, Train Accuracy: 0.7672\n",
      "Epoch [6/50], Loss: 0.3168, Train Accuracy: 0.7672\n",
      "Epoch [7/50], Loss: 0.3143, Train Accuracy: 0.7672\n",
      "Epoch [8/50], Loss: 0.3156, Train Accuracy: 0.7672\n",
      "Epoch [9/50], Loss: 0.3169, Train Accuracy: 0.7672\n",
      "Epoch [10/50], Loss: 0.3153, Train Accuracy: 0.7672\n",
      "Epoch [11/50], Loss: 0.3138, Train Accuracy: 0.7672\n",
      "Epoch [12/50], Loss: 0.3149, Train Accuracy: 0.7672\n",
      "Epoch [13/50], Loss: 0.3138, Train Accuracy: 0.7672\n",
      "Epoch [14/50], Loss: 0.3141, Train Accuracy: 0.7672\n",
      "Epoch [15/50], Loss: 0.3157, Train Accuracy: 0.7672\n",
      "Epoch [16/50], Loss: 0.3130, Train Accuracy: 0.7672\n",
      "Epoch [17/50], Loss: 0.3124, Train Accuracy: 0.7672\n",
      "Epoch [18/50], Loss: 0.3140, Train Accuracy: 0.7672\n",
      "Epoch [19/50], Loss: 0.3132, Train Accuracy: 0.7672\n",
      "Epoch [20/50], Loss: 0.3140, Train Accuracy: 0.7672\n",
      "Epoch [21/50], Loss: 0.3133, Train Accuracy: 0.7672\n",
      "Epoch [22/50], Loss: 0.3124, Train Accuracy: 0.7672\n",
      "Epoch [23/50], Loss: 0.3104, Train Accuracy: 0.7672\n",
      "Epoch [24/50], Loss: 0.3108, Train Accuracy: 0.7672\n",
      "Epoch [25/50], Loss: 0.3136, Train Accuracy: 0.7672\n",
      "Epoch [26/50], Loss: 0.3119, Train Accuracy: 0.7672\n",
      "Epoch [27/50], Loss: 0.3123, Train Accuracy: 0.7672\n",
      "Epoch [28/50], Loss: 0.3102, Train Accuracy: 0.7672\n",
      "Epoch [29/50], Loss: 0.3109, Train Accuracy: 0.7672\n",
      "Epoch [30/50], Loss: 0.3091, Train Accuracy: 0.7672\n",
      "Epoch [31/50], Loss: 0.3092, Train Accuracy: 0.7672\n",
      "Epoch [32/50], Loss: 0.3094, Train Accuracy: 0.7672\n",
      "Epoch [33/50], Loss: 0.3104, Train Accuracy: 0.7672\n",
      "Epoch [34/50], Loss: 0.3090, Train Accuracy: 0.7672\n",
      "Epoch [35/50], Loss: 0.3102, Train Accuracy: 0.7672\n",
      "Epoch [36/50], Loss: 0.3101, Train Accuracy: 0.7672\n",
      "Epoch [37/50], Loss: 0.3077, Train Accuracy: 0.7672\n",
      "Epoch [38/50], Loss: 0.3079, Train Accuracy: 0.7672\n",
      "Epoch [39/50], Loss: 0.3064, Train Accuracy: 0.7672\n",
      "Epoch [40/50], Loss: 0.3079, Train Accuracy: 0.7672\n",
      "Epoch [41/50], Loss: 0.3069, Train Accuracy: 0.7672\n",
      "Epoch [42/50], Loss: 0.3070, Train Accuracy: 0.7672\n",
      "Epoch [43/50], Loss: 0.3083, Train Accuracy: 0.7672\n",
      "Epoch [44/50], Loss: 0.3063, Train Accuracy: 0.7672\n",
      "Epoch [45/50], Loss: 0.3059, Train Accuracy: 0.7672\n",
      "Epoch [46/50], Loss: 0.3047, Train Accuracy: 0.7672\n",
      "Epoch [47/50], Loss: 0.3036, Train Accuracy: 0.7672\n",
      "Epoch [48/50], Loss: 0.3044, Train Accuracy: 0.7672\n",
      "Epoch [49/50], Loss: 0.3033, Train Accuracy: 0.7672\n",
      "Epoch [50/50], Loss: 0.3045, Train Accuracy: 0.7672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # optimizer.zero_grad()\n",
    "    outputs = net(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # converting to binary just to get the accuracy\n",
    "    binary_y_train = (y_train >= 0.5).astype(int)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_outputs = net(X_train_tensor)\n",
    "        train_predicted_labels = (train_outputs >= 0.5).squeeze().cpu().numpy()\n",
    "        train_accuracy = accuracy_score(binary_y_train, train_predicted_labels)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5492bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1101\n",
      "Accuracy: 0.8452, F1-score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    test_outputs = net(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor.view(-1, 1))\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "    # Convert predictions to binary labels\n",
    "    predicted_labels = (test_outputs >= 0.5).squeeze().cpu().numpy()\n",
    "    \n",
    "    # Convert the continuous labels to binary labels\n",
    "    binary_y_test = (y_test >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate accuracy and F1-score\n",
    "    accuracy = accuracy_score(binary_y_test, predicted_labels)\n",
    "    f1 = f1_score(binary_y_test, predicted_labels)\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37bb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
