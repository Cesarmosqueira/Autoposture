{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from models.experimental import attempt_load\n",
    "import cv2\n",
    "from utils.datasets import letterbox\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from utils.general import non_max_suppression_kpt,strip_optimizer,xyxy2xywh\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts,colors,plot_one_box_kpt\n",
    "import logging\n",
    "import pandas as pd\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_path = 'yolov7-w6-pose.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_model(device, model_path):\n",
    "    x = torch.load(model_path, map_location=torch.device(device))\n",
    "\n",
    "    if x.get('ema'):\n",
    "        x['model'] = x['ema']  # replace model with ema\n",
    "    for k in 'optimizer', 'training_results', 'wandb_id', 'ema', 'updates':  # keys\n",
    "        x[k] = None\n",
    "    x['epoch'] = -1\n",
    "    if device!='cpu':\n",
    "        x['model'].half()  # to FP16\n",
    "    else:\n",
    "        x['model'].float()\n",
    "    for p in x['model'].parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    torch.save(x, model_path)\n",
    "    mb = os.path.getsize(model_path) / 1E6  # filesize\n",
    "    print(f\"Optimizer stripped from {model_path},{(f' saved as {model_path},') if model_path else ''} {mb:.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from yolov7-w6-pose.pt, saved as yolov7-w6-pose.pt, 161.1MB\n",
      "Fusing layers... \n"
     ]
    }
   ],
   "source": [
    "strip_model(device, model_path)\n",
    "model = attempt_load(model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Things to identify: ['person']\n"
     ]
    }
   ],
   "source": [
    "_ = model.eval()\n",
    "names = model.module.names if hasattr(model, 'module') else model.names  # get class names\n",
    "print(f\"Things to identify: {names}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open Video capture:\n",
    " - integer that represents a webcam\n",
    " - path to a video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(source):\n",
    "    if source.isnumeric() :    \n",
    "        cap = cv2.VideoCapture(int(source))    #pass video to videocapture object\n",
    "    else :\n",
    "        cap = cv2.VideoCapture(source)    #pass video to videocapture object\n",
    "    if cap.isOpened() == False:   #check if videocapture not opened\n",
    "        print('Source not found. Check path')\n",
    "    else:\n",
    "        frame_width = int(cap.get(3))  #get video frame width\n",
    "        frame_height = int(cap.get(4)) #get video frame height\n",
    "    return cap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over frames\n",
    "For the process of retrieving sequences of landmarks, we will have a `sequence_length` which is the amount of frames taken into consideration for a single sequence of landmark. And also we will have a `separation` which is the amount of frames *ignored* between one set of landmarks and another inside one sequence of landmarks.\n",
    "\n",
    "We will capture landmarks every `separation` and from those captured we will create `N` arrays of length `sequence_length` containing those landmarks \n",
    "\n",
    "### How will we identify the same person in every iteration\n",
    "First, identify the object with more landmarks identified and store that set of landmarks in `base_landmarks`. Then considering the distance between `base_landmarks` and the other objects identified in the next objects identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sequence row:\n",
    "    Video Timestamp Set of landmarks \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def landmarks_sequence_for_video(video_path, sequence_length=10, separation=6):\n",
    "    \"\"\"\n",
    "        Args\n",
    "        Returns\n",
    "    \"\"\"\n",
    "    sequence_length = sequence_length\n",
    "    separation = separation\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    sequences = [[]]\n",
    "\n",
    "    cap = load_source(video_path)\n",
    "    frame_width = int(cap.get(3)) \n",
    "    frame_height = int(cap.get(4))\n",
    "    \n",
    "    base_landmarks = None\n",
    "    \n",
    "    start = time.time()\n",
    "    current_frame = 0\n",
    "    video_name = video_path.split('/')[-1]\n",
    "    current_group = 1\n",
    "    while(cap.isOpened): \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:        \n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        orig_image = frame #store frame\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB) #convert frame to RGB\n",
    "        image = letterbox(image, (frame_width), stride=64, auto=True)[0]\n",
    "        image_ = image.copy()\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = torch.tensor(np.array([image.numpy()]))\n",
    "\n",
    "        image = image.to(device)  #convert image data to device\n",
    "        image = image.float() #convert image to float precision (cpu)      \n",
    "\n",
    "\n",
    "        image = image.cpu().squeeze().numpy().transpose((1, 2, 0))\n",
    "        \n",
    "        # this frame size works with yolov7, since we don't want to touch their model, we just resize the frame.\n",
    "        desired_width = 640\n",
    "        desired_height = 512\n",
    "        image = cv2.resize(image, (desired_width, desired_height), interpolation=cv2.INTER_LINEAR)\n",
    "        image = image[:desired_height, :desired_width]\n",
    "\n",
    "        # Convert the cropped image back to a torch.Tensor\n",
    "        image = torch.from_numpy(image.transpose((2, 0, 1))).unsqueeze(0).cuda()  \n",
    "\n",
    "        with torch.no_grad():  #get predictions\n",
    "            output_data, _ = model(image)\n",
    "\n",
    "        output_data = non_max_suppression_kpt(output_data,   #Apply non max suppression\n",
    "                                        0.25, # Conf. Threshold.\n",
    "                                        0.65, # IoU Threshold.\n",
    "                                        nc=model.yaml['nc'], # Number of classes.\n",
    "                                        nkpt=model.yaml['nkpt'], # Number of keypoints.\n",
    "                                        kpt_label=True)\n",
    "\n",
    "        output = output_to_keypoint(output_data)\n",
    "\n",
    "        im0 = image[0].permute(1, 2, 0) * 255 # Change format [b, c, h, w] to [h, w, c] for displaying the image.\n",
    "        im0 = im0.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        im0 = cv2.cvtColor(im0, cv2.COLOR_RGB2BGR) #reshape image format to (BGR)\n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "\n",
    "        for i, pose in enumerate(output_data):  # detections per image   \n",
    "            if len(output_data):  #check if no pose\n",
    "                for c in pose[:, 5].unique(): # Print results\n",
    "                    n = (pose[:, 5] == c).sum()  # detections per class\n",
    "\n",
    "                for det_index, (*xyxy, conf, cls) in enumerate(reversed(pose[:,:6])): #loop over poses for drawing on frame\n",
    "                    c = int(cls)  # integer class\n",
    "                    kpts = pose[det_index, 6:]\n",
    "                    label = None # if opt.hide_labels else (names[c] if opt.hide_conf else f'{names[c]} {conf:.2f}')\n",
    "                    plot_one_box_kpt(xyxy, im0, label=label, color=colors(c, True), \n",
    "                                    line_thickness=3,kpt_label=True, kpts=kpts, steps=3, \n",
    "                                    orig_shape=im0.shape[:2])\n",
    "\n",
    "\n",
    "        if count == separation:\n",
    "            # cv2.imshow(\"YOLOv7 Pose Estimation Demo\", im0)\n",
    "\n",
    "            if len(sequences[-1]) >= sequence_length:\n",
    "                sequences += [[]] # init new empty sequence\n",
    "                current_group += 1\n",
    "            else:\n",
    "                # TODO: make sure that the landmarks stored are the desired ones\n",
    "                # Use position difference.\n",
    "                if len(output):\n",
    "                    sequences[-1] += [[video_name, current_group, current_frame, output[0]]]\n",
    "\n",
    "            count = 0\n",
    "            \n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        current_frame += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"\\tfinished after {round(time.time() - start)}s\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset_videos/video3.mp4', '../dataset_videos/video11.mp4', '../dataset_videos/video5.mp4', '../dataset_videos/video4.mp4', '../dataset_videos/video2.mp4', '../dataset_videos/video9.mp4', '../dataset_videos/video7.mp4', '../dataset_videos/video1.mp4', '../dataset_videos/video10.mp4', '../dataset_videos/video8.mp4', '../dataset_videos/video6.mp4']\n"
     ]
    }
   ],
   "source": [
    "# landmark retrieval\n",
    "videos = ['../dataset_videos/' + v for v in os.listdir('../dataset_videos') if v.endswith('.mp4')]\n",
    "dataset = []\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video #0 at '../dataset_videos/video3.mp4'\n",
      "\tfinished after 15s\n",
      "Processing video #1 at '../dataset_videos/video11.mp4'\n",
      "\tfinished after 16s\n",
      "Processing video #2 at '../dataset_videos/video5.mp4'\n",
      "\tfinished after 14s\n",
      "Processing video #3 at '../dataset_videos/video4.mp4'\n",
      "\tfinished after 29s\n",
      "Processing video #4 at '../dataset_videos/video2.mp4'\n",
      "\tfinished after 14s\n",
      "Processing video #5 at '../dataset_videos/video9.mp4'\n",
      "\tfinished after 16s\n",
      "Processing video #6 at '../dataset_videos/video7.mp4'\n",
      "\tfinished after 19s\n",
      "Processing video #7 at '../dataset_videos/video1.mp4'\n",
      "\tfinished after 27s\n",
      "Processing video #8 at '../dataset_videos/video10.mp4'\n",
      "\tfinished after 17s\n",
      "Processing video #9 at '../dataset_videos/video8.mp4'\n",
      "\tfinished after 25s\n",
      "Processing video #10 at '../dataset_videos/video6.mp4'\n",
      "\tfinished after 25s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, v in enumerate(videos):\n",
    "    print(f\"Processing video #{i} at '{v}'\")\n",
    "    sequences = landmarks_sequence_for_video(v)\n",
    "    dataset += [sequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this merges every set of landmarks. \n",
    "flatten_data = list(itertools.chain.from_iterable(dataset))\n",
    "flatten_data = list(itertools.chain.from_iterable(flatten_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns='video group frame landmarks'.split(), data=flatten_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>group</th>\n",
       "      <th>frame</th>\n",
       "      <th>landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 288.6236572265625, 254.746490478515...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 287.17803955078125, 255.04141235351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.0, 284.1394348144531, 255.173675537109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 284.852294921875, 255.7018127441406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.0, 0.0, 285.8050842285156, 255.485870361328...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        video  group  frame                                          landmarks\n",
       "0  video3.mp4      1      5  [0.0, 0.0, 288.6236572265625, 254.746490478515...\n",
       "1  video3.mp4      1     11  [0.0, 0.0, 287.17803955078125, 255.04141235351...\n",
       "2  video3.mp4      1     17  [0.0, 0.0, 284.1394348144531, 255.173675537109...\n",
       "3  video3.mp4      1     23  [0.0, 0.0, 284.852294921875, 255.7018127441406...\n",
       "4  video3.mp4      1     29  [0.0, 0.0, 285.8050842285156, 255.485870361328..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>group</th>\n",
       "      <th>frame</th>\n",
       "      <th>landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 288.6236572265625, 254.746490478515...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 287.17803955078125, 255.04141235351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.0, 284.1394348144531, 255.173675537109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 284.852294921875, 255.7018127441406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.0, 0.0, 285.8050842285156, 255.485870361328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>[0.0, 0.0, 286.5685729980469, 255.159271240234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>[0.0, 0.0, 287.4775695800781, 255.432556152343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>[0.0, 0.0, 287.8537902832031, 254.998214721679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>[0.0, 0.0, 288.13385009765625, 254.36953735351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>[0.0, 0.0, 289.3445739746094, 254.191192626953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>[0.0, 0.0, 292.22833251953125, 254.13818359375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.0, 0.0, 293.0972595214844, 254.262634277343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>[0.0, 0.0, 294.19854736328125, 254.09841918945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>[0.0, 0.0, 296.77923583984375, 254.078125, 291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>[0.0, 0.0, 297.80450439453125, 254.12316894531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>[0.0, 0.0, 298.96923828125, 254.1276092529297,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>[0.0, 0.0, 299.5884704589844, 254.086669921875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>[0.0, 0.0, 299.32293701171875, 254.02523803710...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>[0.0, 0.0, 298.1875915527344, 254.004928588867...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>[0.0, 0.0, 301.26763916015625, 253.78877258300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>[0.0, 0.0, 297.35894775390625, 254.38638305664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>[0.0, 0.0, 297.4754638671875, 257.347961425781...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>[0.0, 0.0, 298.2802734375, 259.6361083984375, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>155</td>\n",
       "      <td>[0.0, 0.0, 298.8634033203125, 259.508575439453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0, 0.0, 298.59381103515625, 258.93347167968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>[0.0, 0.0, 296.28179931640625, 259.39361572265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>[0.0, 0.0, 295.87786865234375, 260.03195190429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>[0.0, 0.0, 296.442626953125, 260.6909484863281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>[0.0, 0.0, 295.4737548828125, 261.370483398437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>[0.0, 0.0, 293.8111572265625, 260.405670166015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>203</td>\n",
       "      <td>[0.0, 0.0, 291.682373046875, 261.3394470214844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "      <td>[0.0, 0.0, 291.3133544921875, 261.322113037109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>215</td>\n",
       "      <td>[0.0, 0.0, 290.732666015625, 263.7330627441406...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video  group  frame   \n",
       "0   video3.mp4      1      5  \\\n",
       "1   video3.mp4      1     11   \n",
       "2   video3.mp4      1     17   \n",
       "3   video3.mp4      1     23   \n",
       "4   video3.mp4      1     29   \n",
       "5   video3.mp4      1     35   \n",
       "6   video3.mp4      1     41   \n",
       "7   video3.mp4      1     47   \n",
       "8   video3.mp4      1     53   \n",
       "9   video3.mp4      1     59   \n",
       "10  video3.mp4      2     71   \n",
       "11  video3.mp4      2     77   \n",
       "12  video3.mp4      2     83   \n",
       "13  video3.mp4      2     89   \n",
       "14  video3.mp4      2     95   \n",
       "15  video3.mp4      2    101   \n",
       "16  video3.mp4      2    107   \n",
       "17  video3.mp4      2    113   \n",
       "18  video3.mp4      2    119   \n",
       "19  video3.mp4      2    125   \n",
       "20  video3.mp4      3    137   \n",
       "21  video3.mp4      3    143   \n",
       "22  video3.mp4      3    149   \n",
       "23  video3.mp4      3    155   \n",
       "24  video3.mp4      3    161   \n",
       "25  video3.mp4      3    167   \n",
       "26  video3.mp4      3    173   \n",
       "27  video3.mp4      3    179   \n",
       "28  video3.mp4      3    185   \n",
       "29  video3.mp4      3    191   \n",
       "30  video3.mp4      4    203   \n",
       "31  video3.mp4      4    209   \n",
       "32  video3.mp4      4    215   \n",
       "\n",
       "                                            landmarks  \n",
       "0   [0.0, 0.0, 288.6236572265625, 254.746490478515...  \n",
       "1   [0.0, 0.0, 287.17803955078125, 255.04141235351...  \n",
       "2   [0.0, 0.0, 284.1394348144531, 255.173675537109...  \n",
       "3   [0.0, 0.0, 284.852294921875, 255.7018127441406...  \n",
       "4   [0.0, 0.0, 285.8050842285156, 255.485870361328...  \n",
       "5   [0.0, 0.0, 286.5685729980469, 255.159271240234...  \n",
       "6   [0.0, 0.0, 287.4775695800781, 255.432556152343...  \n",
       "7   [0.0, 0.0, 287.8537902832031, 254.998214721679...  \n",
       "8   [0.0, 0.0, 288.13385009765625, 254.36953735351...  \n",
       "9   [0.0, 0.0, 289.3445739746094, 254.191192626953...  \n",
       "10  [0.0, 0.0, 292.22833251953125, 254.13818359375...  \n",
       "11  [0.0, 0.0, 293.0972595214844, 254.262634277343...  \n",
       "12  [0.0, 0.0, 294.19854736328125, 254.09841918945...  \n",
       "13  [0.0, 0.0, 296.77923583984375, 254.078125, 291...  \n",
       "14  [0.0, 0.0, 297.80450439453125, 254.12316894531...  \n",
       "15  [0.0, 0.0, 298.96923828125, 254.1276092529297,...  \n",
       "16  [0.0, 0.0, 299.5884704589844, 254.086669921875...  \n",
       "17  [0.0, 0.0, 299.32293701171875, 254.02523803710...  \n",
       "18  [0.0, 0.0, 298.1875915527344, 254.004928588867...  \n",
       "19  [0.0, 0.0, 301.26763916015625, 253.78877258300...  \n",
       "20  [0.0, 0.0, 297.35894775390625, 254.38638305664...  \n",
       "21  [0.0, 0.0, 297.4754638671875, 257.347961425781...  \n",
       "22  [0.0, 0.0, 298.2802734375, 259.6361083984375, ...  \n",
       "23  [0.0, 0.0, 298.8634033203125, 259.508575439453...  \n",
       "24  [0.0, 0.0, 298.59381103515625, 258.93347167968...  \n",
       "25  [0.0, 0.0, 296.28179931640625, 259.39361572265...  \n",
       "26  [0.0, 0.0, 295.87786865234375, 260.03195190429...  \n",
       "27  [0.0, 0.0, 296.442626953125, 260.6909484863281...  \n",
       "28  [0.0, 0.0, 295.4737548828125, 261.370483398437...  \n",
       "29  [0.0, 0.0, 293.8111572265625, 260.405670166015...  \n",
       "30  [0.0, 0.0, 291.682373046875, 261.3394470214844...  \n",
       "31  [0.0, 0.0, 291.3133544921875, 261.322113037109...  \n",
       "32  [0.0, 0.0, 290.732666015625, 263.7330627441406...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['video'] == 'video3.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
