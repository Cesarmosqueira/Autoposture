{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from models.experimental import attempt_load\n",
    "import cv2\n",
    "from utils.datasets import letterbox\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from utils.general import non_max_suppression_kpt,strip_optimizer,xyxy2xywh\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts,colors,plot_one_box_kpt\n",
    "import logging\n",
    "import pandas as pd\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_path = '../models/yolov7-w6-pose.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_model(device, model_path):\n",
    "    x = torch.load(model_path, map_location=torch.device(device))\n",
    "\n",
    "    if x.get('ema'):\n",
    "        x['model'] = x['ema']  # replace model with ema\n",
    "    for k in 'optimizer', 'training_results', 'wandb_id', 'ema', 'updates':  # keys\n",
    "        x[k] = None\n",
    "    x['epoch'] = -1\n",
    "    if device!='cpu':\n",
    "        x['model'].half()  # to FP16\n",
    "    else:\n",
    "        x['model'].float()\n",
    "    for p in x['model'].parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    torch.save(x, model_path)\n",
    "    mb = os.path.getsize(model_path) / 1E6  # filesize\n",
    "    print(f\"Optimizer stripped from {model_path},{(f' saved as {model_path},') if model_path else ''} {mb:.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from ../models/yolov7-w6-pose.pt, saved as ../models/yolov7-w6-pose.pt, 161.1MB\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g/.local/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "strip_model(device, model_path)\n",
    "model = attempt_load(model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Things to identify: ['person']\n"
     ]
    }
   ],
   "source": [
    "_ = model.eval()\n",
    "names = model.module.names if hasattr(model, 'module') else model.names  # get class names\n",
    "print(f\"Things to identify: {names}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open Video capture:\n",
    " - integer that represents a webcam\n",
    " - path to a video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(source):\n",
    "    if source.isnumeric() :    \n",
    "        cap = cv2.VideoCapture(int(source))    #pass video to videocapture object\n",
    "    else :\n",
    "        cap = cv2.VideoCapture(source)    #pass video to videocapture object\n",
    "    if cap.isOpened() == False:   #check if videocapture not opened\n",
    "        print('Source not found. Check path')\n",
    "    else:\n",
    "        frame_width = int(cap.get(3))  #get video frame width\n",
    "        frame_height = int(cap.get(4)) #get video frame height\n",
    "    return cap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over frames\n",
    "For the process of retrieving sequences of landmarks, we will have a `sequence_length` which is the amount of frames taken into consideration for a single sequence of landmark. And also we will have a `separation` which is the amount of frames *ignored* between one set of landmarks and another inside one sequence of landmarks.\n",
    "\n",
    "We will capture landmarks every `separation` and from those captured we will create `N` arrays of length `sequence_length` containing those landmarks \n",
    "\n",
    "### How will we identify the same person in every iteration\n",
    "First, identify the object with more landmarks identified and store that set of landmarks in `base_landmarks`. Then considering the distance between `base_landmarks` and the other objects identified in the next objects identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sequence row:\n",
    "    Video Timestamp Set of landmarks \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def landmarks_sequence_for_video(video_path, sequence_length=10, separation=6):\n",
    "    \"\"\"\n",
    "        Args\n",
    "        Returns\n",
    "    \"\"\"\n",
    "    sequence_length = sequence_length\n",
    "    separation = separation\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    sequences = [[]]\n",
    "\n",
    "    cap = load_source(video_path)\n",
    "    frame_width = int(cap.get(3)) \n",
    "    frame_height = int(cap.get(4))\n",
    "    \n",
    "    base_landmarks = None\n",
    "    \n",
    "    start = time.time()\n",
    "    current_frame = 0\n",
    "    video_name = video_path.split('/')[-1]\n",
    "    current_group = 1\n",
    "    while(cap.isOpened): \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:        \n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        orig_image = frame #store frame\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB) #convert frame to RGB\n",
    "        image = letterbox(image, (frame_width), stride=64, auto=True)[0]\n",
    "        image_ = image.copy()\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = torch.tensor(np.array([image.numpy()]))\n",
    "\n",
    "        image = image.to(device)  #convert image data to device\n",
    "        image = image.float() #convert image to float precision (cpu)      \n",
    "\n",
    "\n",
    "        image = image.cpu().squeeze().numpy().transpose((1, 2, 0))\n",
    "        \n",
    "        # this frame size works with yolov7, since we don't want to touch their model, we just resize the frame.\n",
    "        desired_width = 640\n",
    "        desired_height = 512\n",
    "        image = cv2.resize(image, (desired_width, desired_height), interpolation=cv2.INTER_LINEAR)\n",
    "        image = image[:desired_height, :desired_width]\n",
    "\n",
    "        # Convert the cropped image back to a torch.Tensor\n",
    "        image = torch.from_numpy(image.transpose((2, 0, 1))).unsqueeze(0).cuda()  \n",
    "\n",
    "        with torch.no_grad():  #get predictions\n",
    "            output_data, _ = model(image)\n",
    "\n",
    "        output_data = non_max_suppression_kpt(output_data,   #Apply non max suppression\n",
    "                                        0.25, # Conf. Threshold.\n",
    "                                        0.65, # IoU Threshold.\n",
    "                                        nc=model.yaml['nc'], # Number of classes.\n",
    "                                        nkpt=model.yaml['nkpt'], # Number of keypoints.\n",
    "                                        kpt_label=True)\n",
    "\n",
    "        output = output_to_keypoint(output_data)\n",
    "\n",
    "        im0 = image[0].permute(1, 2, 0) * 255 # Change format [b, c, h, w] to [h, w, c] for displaying the image.\n",
    "        im0 = im0.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        im0 = cv2.cvtColor(im0, cv2.COLOR_RGB2BGR) #reshape image format to (BGR)\n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "\n",
    "        for i, pose in enumerate(output_data):  # detections per image   \n",
    "            if len(output_data):  #check if no pose\n",
    "                for c in pose[:, 5].unique(): # Print results\n",
    "                    n = (pose[:, 5] == c).sum()  # detections per class\n",
    "\n",
    "                for det_index, (*xyxy, conf, cls) in enumerate(reversed(pose[:,:6])): #loop over poses for drawing on frame\n",
    "                    c = int(cls)  # integer class\n",
    "                    kpts = pose[det_index, 6:]\n",
    "                    label = None # if opt.hide_labels else (names[c] if opt.hide_conf else f'{names[c]} {conf:.2f}')\n",
    "                    plot_one_box_kpt(xyxy, im0, label=label, color=colors(c, True), \n",
    "                                    line_thickness=3,kpt_label=True, kpts=kpts, steps=3, \n",
    "                                    orig_shape=im0.shape[:2])\n",
    "\n",
    "\n",
    "        if count == separation:\n",
    "            # cv2.imshow(\"YOLOv7 Pose Estimation Demo\", im0)\n",
    "\n",
    "            if len(sequences[-1]) >= sequence_length:\n",
    "                sequences += [[]] # init new empty sequence\n",
    "                current_group += 1\n",
    "            else:\n",
    "                # TODO: make sure that the landmarks stored are the desired ones\n",
    "                # Use position difference.\n",
    "                if len(output):\n",
    "                    sequences[-1] += [[video_name, current_group, current_frame, output[0]]]\n",
    "\n",
    "            count = 0\n",
    "            \n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        current_frame += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"\\tfinished after {round(time.time() - start)}s\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../assets/dataset_videos/video56.mp4', '../assets/dataset_videos/video30.mp4', '../assets/dataset_videos/video36.mp4', '../assets/dataset_videos/video24.mp4', '../assets/dataset_videos/video37.mp4', '../assets/dataset_videos/video47.mp4', '../assets/dataset_videos/video35.mp4', '../assets/dataset_videos/video31.mp4', '../assets/dataset_videos/video32.mp4', '../assets/dataset_videos/video21.mp4', '../assets/dataset_videos/video26.mp4', '../assets/dataset_videos/video40.mp4', '../assets/dataset_videos/video54.mp4', '../assets/dataset_videos/video20.mp4', '../assets/dataset_videos/video53.mp4', '../assets/dataset_videos/video55.mp4', '../assets/dataset_videos/video50.mp4', '../assets/dataset_videos/video44.mp4', '../assets/dataset_videos/video25.mp4', '../assets/dataset_videos/video41.mp4', '../assets/dataset_videos/video51.mp4', '../assets/dataset_videos/video19.mp4', '../assets/dataset_videos/video38.mp4', '../assets/dataset_videos/video34.mp4', '../assets/dataset_videos/video48.mp4', '../assets/dataset_videos/video33.mp4', '../assets/dataset_videos/video45.mp4', '../assets/dataset_videos/video43.mp4', '../assets/dataset_videos/video27.mp4', '../assets/dataset_videos/video18.mp4', '../assets/dataset_videos/video28.mp4', '../assets/dataset_videos/video29.mp4', '../assets/dataset_videos/video17.mp4', '../assets/dataset_videos/video39.mp4', '../assets/dataset_videos/video23.mp4', '../assets/dataset_videos/video49.mp4', '../assets/dataset_videos/video42.mp4', '../assets/dataset_videos/video52.mp4', '../assets/dataset_videos/video46.mp4', '../assets/dataset_videos/video22.mp4']\n"
     ]
    }
   ],
   "source": [
    "# landmark retrieval\n",
    "videos = ['../assets/dataset_videos/' + v for v in os.listdir('../assets/dataset_videos') if v.endswith('.mp4')]\n",
    "dataset = []\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video #0 at '../dataset_videos/video3.mp4'\n",
      "\tfinished after 19s\n",
      "Processing video #1 at '../dataset_videos/video11.mp4'\n",
      "\tfinished after 16s\n",
      "Processing video #2 at '../dataset_videos/video5.mp4'\n",
      "\tfinished after 46s\n",
      "Processing video #3 at '../dataset_videos/video14.mp4'\n",
      "\tfinished after 14s\n",
      "Processing video #4 at '../dataset_videos/video12.mp4'\n",
      "\tfinished after 31s\n",
      "Processing video #5 at '../dataset_videos/video4.mp4'\n",
      "\tfinished after 27s\n",
      "Processing video #6 at '../dataset_videos/video2.mp4'\n",
      "\tfinished after 19s\n",
      "Processing video #7 at '../dataset_videos/video9.mp4'\n",
      "\tfinished after 17s\n",
      "Processing video #8 at '../dataset_videos/video7.mp4'\n",
      "\tfinished after 12s\n",
      "Processing video #9 at '../dataset_videos/video13.mp4'\n",
      "\tfinished after 10s\n",
      "Processing video #10 at '../dataset_videos/video15.mp4'\n",
      "\tfinished after 51s\n",
      "Processing video #11 at '../dataset_videos/video1.mp4'\n",
      "\tfinished after 18s\n",
      "Processing video #12 at '../dataset_videos/video10.mp4'\n",
      "\tfinished after 33s\n",
      "Processing video #13 at '../dataset_videos/video16.mp4'\n",
      "\tfinished after 22s\n",
      "Processing video #14 at '../dataset_videos/video8.mp4'\n",
      "\tfinished after 16s\n",
      "Processing video #15 at '../dataset_videos/video6.mp4'\n",
      "\tfinished after 54s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, v in enumerate(videos):\n",
    "    print(f\"Processing video #{i} at '{v}'\")\n",
    "    sequences = landmarks_sequence_for_video(v)\n",
    "    dataset += [sequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this merges every set of landmarks. \n",
    "flatten_data = list(itertools.chain.from_iterable(dataset))\n",
    "flatten_data = list(itertools.chain.from_iterable(flatten_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns='video group frame landmarks'.split(), data=flatten_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>group</th>\n",
       "      <th>frame</th>\n",
       "      <th>landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 243.16107177734375, 252.64248657226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 244.4012451171875, 251.631011962890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.0, 242.58554077148438, 252.24295043945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 237.6522216796875, 252.982452392578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.0, 0.0, 224.66685485839844, 254.49746704101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        video  group  frame                                          landmarks\n",
       "0  video3.mp4      1      5  [0.0, 0.0, 243.16107177734375, 252.64248657226...\n",
       "1  video3.mp4      1     11  [0.0, 0.0, 244.4012451171875, 251.631011962890...\n",
       "2  video3.mp4      1     17  [0.0, 0.0, 242.58554077148438, 252.24295043945...\n",
       "3  video3.mp4      1     23  [0.0, 0.0, 237.6522216796875, 252.982452392578...\n",
       "4  video3.mp4      1     29  [0.0, 0.0, 224.66685485839844, 254.49746704101..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../assets/extracted_landmarks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>group</th>\n",
       "      <th>frame</th>\n",
       "      <th>landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 243.16107177734375, 252.64248657226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.0, 244.4012451171875, 251.631011962890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.0, 242.58554077148438, 252.24295043945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.0, 237.6522216796875, 252.982452392578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.0, 0.0, 224.66685485839844, 254.49746704101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>[0.0, 0.0, 214.17312622070312, 251.88236999511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>[0.0, 0.0, 205.13592529296875, 252.50271606445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>[0.0, 0.0, 203.34231567382812, 252.56079101562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>[0.0, 0.0, 207.150634765625, 253.4675903320312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>[0.0, 0.0, 221.7003173828125, 254.099411010742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>[0.0, 0.0, 257.10125732421875, 252.82443237304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.0, 0.0, 253.5900115966797, 252.698059082031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>[0.0, 0.0, 237.93588256835938, 252.87780761718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>[0.0, 0.0, 227.48953247070312, 253.72024536132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>[0.0, 0.0, 221.58209228515625, 253.67303466796...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>[0.0, 0.0, 219.72598266601562, 253.72439575195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>[0.0, 0.0, 215.31240844726562, 252.60783386230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>[0.0, 0.0, 216.686767578125, 252.1822052001953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>[0.0, 0.0, 217.5852813720703, 251.884872436523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>[0.0, 0.0, 223.27420043945312, 252.82025146484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>[0.0, 0.0, 229.95550537109375, 252.15618896484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>[0.0, 0.0, 233.1385498046875, 252.420532226562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>[0.0, 0.0, 237.06971740722656, 252.53805541992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>155</td>\n",
       "      <td>[0.0, 0.0, 239.5977783203125, 252.884323120117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0, 0.0, 239.9578857421875, 252.834838867187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>[0.0, 0.0, 238.658935546875, 252.5682678222656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>[0.0, 0.0, 236.7154541015625, 253.194427490234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>[0.0, 0.0, 232.43614196777344, 253.38180541992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>[0.0, 0.0, 230.56301879882812, 253.13006591796...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>[0.0, 0.0, 229.46493530273438, 253.01651000976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>203</td>\n",
       "      <td>[0.0, 0.0, 234.3992156982422, 251.961608886718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "      <td>[0.0, 0.0, 239.05203247070312, 251.92001342773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>215</td>\n",
       "      <td>[0.0, 0.0, 244.56216430664062, 251.91711425781...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>221</td>\n",
       "      <td>[0.0, 0.0, 248.0079345703125, 250.908782958984...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>video3.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>[0.0, 0.0, 246.793212890625, 250.8934020996093...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video  group  frame   \n",
       "0   video3.mp4      1      5  \\\n",
       "1   video3.mp4      1     11   \n",
       "2   video3.mp4      1     17   \n",
       "3   video3.mp4      1     23   \n",
       "4   video3.mp4      1     29   \n",
       "5   video3.mp4      1     35   \n",
       "6   video3.mp4      1     41   \n",
       "7   video3.mp4      1     47   \n",
       "8   video3.mp4      1     53   \n",
       "9   video3.mp4      1     59   \n",
       "10  video3.mp4      2     71   \n",
       "11  video3.mp4      2     77   \n",
       "12  video3.mp4      2     83   \n",
       "13  video3.mp4      2     89   \n",
       "14  video3.mp4      2     95   \n",
       "15  video3.mp4      2    101   \n",
       "16  video3.mp4      2    107   \n",
       "17  video3.mp4      2    113   \n",
       "18  video3.mp4      2    119   \n",
       "19  video3.mp4      2    125   \n",
       "20  video3.mp4      3    137   \n",
       "21  video3.mp4      3    143   \n",
       "22  video3.mp4      3    149   \n",
       "23  video3.mp4      3    155   \n",
       "24  video3.mp4      3    161   \n",
       "25  video3.mp4      3    167   \n",
       "26  video3.mp4      3    173   \n",
       "27  video3.mp4      3    179   \n",
       "28  video3.mp4      3    185   \n",
       "29  video3.mp4      3    191   \n",
       "30  video3.mp4      4    203   \n",
       "31  video3.mp4      4    209   \n",
       "32  video3.mp4      4    215   \n",
       "33  video3.mp4      4    221   \n",
       "34  video3.mp4      4    227   \n",
       "\n",
       "                                            landmarks  \n",
       "0   [0.0, 0.0, 243.16107177734375, 252.64248657226...  \n",
       "1   [0.0, 0.0, 244.4012451171875, 251.631011962890...  \n",
       "2   [0.0, 0.0, 242.58554077148438, 252.24295043945...  \n",
       "3   [0.0, 0.0, 237.6522216796875, 252.982452392578...  \n",
       "4   [0.0, 0.0, 224.66685485839844, 254.49746704101...  \n",
       "5   [0.0, 0.0, 214.17312622070312, 251.88236999511...  \n",
       "6   [0.0, 0.0, 205.13592529296875, 252.50271606445...  \n",
       "7   [0.0, 0.0, 203.34231567382812, 252.56079101562...  \n",
       "8   [0.0, 0.0, 207.150634765625, 253.4675903320312...  \n",
       "9   [0.0, 0.0, 221.7003173828125, 254.099411010742...  \n",
       "10  [0.0, 0.0, 257.10125732421875, 252.82443237304...  \n",
       "11  [0.0, 0.0, 253.5900115966797, 252.698059082031...  \n",
       "12  [0.0, 0.0, 237.93588256835938, 252.87780761718...  \n",
       "13  [0.0, 0.0, 227.48953247070312, 253.72024536132...  \n",
       "14  [0.0, 0.0, 221.58209228515625, 253.67303466796...  \n",
       "15  [0.0, 0.0, 219.72598266601562, 253.72439575195...  \n",
       "16  [0.0, 0.0, 215.31240844726562, 252.60783386230...  \n",
       "17  [0.0, 0.0, 216.686767578125, 252.1822052001953...  \n",
       "18  [0.0, 0.0, 217.5852813720703, 251.884872436523...  \n",
       "19  [0.0, 0.0, 223.27420043945312, 252.82025146484...  \n",
       "20  [0.0, 0.0, 229.95550537109375, 252.15618896484...  \n",
       "21  [0.0, 0.0, 233.1385498046875, 252.420532226562...  \n",
       "22  [0.0, 0.0, 237.06971740722656, 252.53805541992...  \n",
       "23  [0.0, 0.0, 239.5977783203125, 252.884323120117...  \n",
       "24  [0.0, 0.0, 239.9578857421875, 252.834838867187...  \n",
       "25  [0.0, 0.0, 238.658935546875, 252.5682678222656...  \n",
       "26  [0.0, 0.0, 236.7154541015625, 253.194427490234...  \n",
       "27  [0.0, 0.0, 232.43614196777344, 253.38180541992...  \n",
       "28  [0.0, 0.0, 230.56301879882812, 253.13006591796...  \n",
       "29  [0.0, 0.0, 229.46493530273438, 253.01651000976...  \n",
       "30  [0.0, 0.0, 234.3992156982422, 251.961608886718...  \n",
       "31  [0.0, 0.0, 239.05203247070312, 251.92001342773...  \n",
       "32  [0.0, 0.0, 244.56216430664062, 251.91711425781...  \n",
       "33  [0.0, 0.0, 248.0079345703125, 250.908782958984...  \n",
       "34  [0.0, 0.0, 246.793212890625, 250.8934020996093...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['video'] == 'video3.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
